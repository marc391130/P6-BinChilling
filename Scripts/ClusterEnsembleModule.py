# coding: utf-8


# ClusterEnsembles.py
#   Author: Takehiro Sano
#   Contact: tsano430@gmail.com
#   License: MIT License

#This is taken from: https://github.com/tsano430/ClusterEnsembles
#The create_hypergraph method has been modified to use sparse matricies instead of numpy,
# - as it used too much memory for our usecase when not using sparse.

import os
import warnings
from typing import Optional

import kahypar
import numpy as np
import pymetis
from scipy import sparse
from sklearn.metrics import normalized_mutual_info_score
from sklearn.utils.extmath import safe_sparse_dot
from tqdm import tqdm


def create_hypergraph(labels):
    """Create the incidence matrix of labels' hypergraph.

    Parameter
    ----------
    labels: Labels generated by multiple clustering algorithms such as K-Means.

    Return
    -------
    H: Incidence matrix of labels' hypergraph.
    """
    H = []

    for label in labels:
        label = np.nan_to_num(label, nan=float("inf"))
        unique_label = np.unique(label)
        len_unique_label = len(unique_label)
        label2id = dict(zip(unique_label, np.arange(len_unique_label)))
        tmp = [label2id[elem] for elem in label]
        h = sparse.lil_matrix(np.zeros(shape=(len_unique_label, len_unique_label)), dtype=int)[tmp]
        for i in range(len_unique_label):
            h[i, i] = 1
        # h = np.identity(len_unique_label, dtype=int)[tmp]
        if float("inf") in label2id.keys():
            h = np.delete(h, obj=label2id[float("inf")], axis=1)
        H.append(sparse.csc_matrix(h))

    return sparse.hstack(H)


def to_pymetis_format(adj_mat):
    """Transform an adjacency matrix into the pymetis format.

    Parameter
    ---------
    adj_mat: Adjacency matrix.

    Returns
    -------
    xadj, adjncy, eweights: Parameters for pymetis.
    """
    xadj = [0]
    adjncy = []
    eweights = []
    n_rows = adj_mat.shape[0]
    adj_mat = adj_mat.tolil()

    for i in tqdm(range(n_rows)):
        row = adj_mat.getrow(i)
        idx_row, idx_col = row.nonzero()
        val = row[idx_row, idx_col]
        adjncy += list(idx_col)
        eweights += list(val.toarray()[0])
        xadj.append(len(adjncy))

    return xadj, adjncy, eweights


def cspa(labels, nclass):
    """Cluster-based Similarity Partitioning Algorithm (CSPA).

    Parameters
    ----------
    labels: Labels generated by multiple clustering algorithms such as K-Means.
    nclass: Number of classes in a consensus clustering label.

    Return
    -------
    label_ce: Consensus clustering label obtained from CSPA.
    """
    H = create_hypergraph(labels)
    S = H * H.T

    xadj, adjncy, eweights = to_pymetis_format(S)
    membership = pymetis.part_graph(nparts=nclass, xadj=xadj, adjncy=adjncy, eweights=eweights)[1]
    label_ce = np.array(membership)

    return label_ce


def hgpa(labels, nclass, random_state):
    """HyperGraph Partitioning Algorithm (HGPA).

    Parameters
    ----------
    labels: Labels generated by multiple clustering algorithms such as K-Means.
    nclass: Number of classes in a consensus clustering label.
    random_state: Used for reproducible results.

    Return
    -------
    label_ce: Consensus clustering label obtained from HGPA.
    """
    # Create hypergraph for kahypar
    H = create_hypergraph(labels)
    n_nodes, n_nets = H.shape

    node_weights = [1] * n_nodes
    edge_weights = [1] * n_nets

    hyperedge_indices = [0]
    hyperedges = []
    HT = H.T
    for i in range(n_nets):
        h = HT.getrow(i)
        idx_row, idx_col = h.nonzero()
        hyperedges += list(idx_col)
        hyperedge_indices.append(len(hyperedges))

    hypergraph = kahypar.Hypergraph(n_nodes, n_nets, hyperedge_indices, hyperedges, nclass, edge_weights, node_weights)

    # Settings for kahypar
    context = kahypar.Context()
    config_path = os.path.dirname(__file__) + "/kahypar_config/km1_kKaHyPar_sea20.ini"
    context.loadINIconfiguration(config_path)
    if random_state is not None:
        context.setSeed(random_state)
    context.setK(nclass)
    context.setEpsilon(0.03)
    context.suppressOutput(True)

    # Hypergraph partitioning
    kahypar.partition(hypergraph, context)

    label_ce = np.empty(n_nodes, dtype=int)
    for i in range(n_nodes):
        label_ce[i] = hypergraph.blockID(i)

    return label_ce


def mcla(labels, nclass, random_state):
    """Meta-CLustering Algorithm (MCLA).

    Parameters
    ----------
    labels: Labels generated by multiple clustering algorithms such as K-Means.
    nclass: Number of classes in a consensus clustering label.
    random_state: Used for reproducible results.

    Return
    -------
    label_ce: Consensus clustering label obtained from MCLA.
    """
    np.random.seed(random_state)

    # Construct Meta-graph
    H = create_hypergraph(labels)
    n_cols = H.shape[1]

    W = sparse.identity(n_cols, dtype=float, format="lil")
    for i in range(n_cols):
        hi = H.getcol(i)
        norm_hi = (hi.T * hi)[0, 0]
        for j in range(n_cols):
            if i < j:
                hj = H.getcol(j)
                norm_hj = (hj.T * hj)[0, 0]
                inner_prod = (hi.T * hj)[0, 0]
                W[i, j] = inner_prod / (norm_hi + norm_hj - inner_prod)
                W[j, i] = W[i, j]
    W *= 1e3
    W = W.astype(int)

    # Cluster Hyperedges
    xadj, adjncy, eweights = to_pymetis_format(W)
    membership = pymetis.part_graph(nparts=nclass, xadj=xadj, adjncy=adjncy, eweights=eweights)[1]

    # Collapse Meta-clusters
    meta_clusters = sparse.dok_matrix((labels.shape[1], nclass), dtype=float).tolil()
    for i, v in enumerate(membership):
        meta_clusters[:, v] += H.getcol(i)

    # Compete for Objects
    label_ce = np.empty(labels.shape[1], dtype=int)
    for i, v in enumerate(meta_clusters):
        v = v.toarray()[0]
        label_ce[i] = np.random.choice(np.nonzero(v == np.max(v))[0])

    return label_ce


def hbgf(labels, nclass):
    """Hybrid Bipartite Graph Formulation (HBGF).

    Parameters
    ----------
    labels: Labels generated by multiple clustering algorithms such as K-Means.
    nclass: Number of classes in a consensus clustering label.

    Return
    -------
    label_ce: Consensus clustering label obtained from HBGF.
    """
    A = create_hypergraph(labels)
    n_rows, n_cols = A.shape
    W = sparse.bmat([[sparse.dok_matrix((n_cols, n_cols)), A.T], [A, sparse.dok_matrix((n_rows, n_rows))]])
    xadj, adjncy, _ = to_pymetis_format(W)
    membership = pymetis.part_graph(nparts=nclass, xadj=xadj, adjncy=adjncy, eweights=None)[1]
    label_ce = np.array(membership[n_cols:])
    return label_ce


def create_connectivity_matrix(labels):
    """Create the connectivity matrix.

    Parameter
    ---------
    labels: Labels generated by multiple clustering algorithms such as K-Means.

    Return
    ------
    M: Connectivity matrix.
    """
    n_labels, len_labels = labels.shape
    M = np.zeros((len_labels, len_labels))
    m = np.zeros_like(M)

    for label in labels:
        for i, elem in enumerate(label):
            m[i] = np.where(elem == label, 1, 0)
        M += m

    M /= n_labels
    return sparse.csr_matrix(M)


def orthogonal_nmf_algorithm(W, nclass, random_state, maxiter):
    """Algorithm for bi-orthogonal three-factor NMF problem.

    Parameters
    ----------
    W: Given matrix.
    random_state: Used for reproducible results.
    maxiter: Maximum number of iterations.

    Return
    -------
    Q, S: Factor matrices.
    """
    np.random.seed(random_state)

    n = W.shape[0]
    Q = np.random.rand(n, nclass).reshape(n, nclass)
    S = np.diag(np.random.rand(nclass))

    for _ in range(maxiter):
        # Update Q
        WQS = safe_sparse_dot(W, np.dot(Q, S), dense_output=True)
        Q = Q * np.sqrt(WQS / (np.dot(Q, np.dot(Q.T, WQS)) + 1e-8))
        # Update S
        QTQ = np.dot(Q.T, Q)
        WQ = safe_sparse_dot(W, Q, dense_output=False)
        QTWQ = safe_sparse_dot(Q.T, WQ, dense_output=True)
        S = S * np.sqrt(QTWQ / (np.dot(QTQ, np.dot(S, QTQ)) + 1e-8))

    return Q, S


def nmf(labels, nclass, random_state, maxiter=200):
    """NMF-based consensus clustering.

    Parameters
    ----------
    labels: Labels generated by multiple clustering algorithms such as K-Means.
    nclass: Number of classes in a consensus clustering label.
    random_state: Used for reproducible results.
    maxiter: Maximum number of iterations.

    Return
    -------
    label_ce: Consensus clustering label obtained from NMF.
    """
    M = create_connectivity_matrix(labels)
    Q, S = orthogonal_nmf_algorithm(M, nclass, random_state, maxiter)
    label_ce = np.argmax(np.dot(Q, np.sqrt(S)), axis=1)
    return label_ce


def calc_objective(labels, label_ce):
    """Calculate the objective function value for cluster ensembles.

    Parameters
    ----------
    labels: Labels generated by multiple clustering algorithms such as K-Means.
    label_ce: Consensus clustering label.

    Return
    -------
    objv: Objective function value.
    """
    objv = 0.0
    for label in labels:
        idx = np.isfinite(label)
        objv += normalized_mutual_info_score(label_ce[idx], label[idx], average_method="geometric")
    objv /= labels.shape[0]
    return objv


def cluster_ensembles(
    labels: np.ndarray,
    nclass: Optional[int] = None,
    solver: str = "hbgf",
    random_state: Optional[int] = None,
    verbose: bool = False,
) -> np.ndarray:
    """Generate a single consensus clustering label by using base labels
       obtained from multiple clustering algorithms.

    Parameters
    ----------
    labels: Labels generated by multiple clustering algorithms such as K-Means.
    nclass: Number of classes in a consensus clustering label.
    solver: Solver type for cluster ensembles.
    random_state: Used for 'hgpa', 'mcla', and 'nmf'.
                  Please pass a nonnegative integer for reproducible results.
    verbose: Whether to be verbose.

    Return
    -------
    label_ce: Consensus clustering label.
    """
    if nclass is None:
        nclass = -1
        for label in labels:
            len_unique_label = len(np.unique(label[~np.isnan(label)]))
            nclass = max(nclass, len_unique_label)

    if verbose:
        print("Cluster Ensembles")
        print("    - Number of classes:", nclass)
        print("    - Solver:", solver)
        print("    - Length of labels:", labels.shape[1])
        print("    - Number of labels:", labels.shape[0])

    if not (isinstance(nclass, int) and nclass > 0):
        raise ValueError(f"Number of class must be a positive integer; got (nclass={nclass})")

    if not ((random_state is None) or isinstance(random_state, int)):
        raise ValueError(f"Number of random_state must be an integer; got (random_state={random_state})")

    if isinstance(random_state, int):
        random_state = abs(random_state)

    if solver == "cspa":
        if labels.shape[1] > 5000:
            warnings.warn("The length of labels is very large, so another solvers are recommended.")
        label_ce = cspa(labels, nclass)
    elif solver == "hgpa":
        label_ce = hgpa(labels, nclass, random_state)
    elif solver == "mcla":
        label_ce = mcla(labels, nclass, random_state)
    elif solver == "hbgf":
        label_ce = hbgf(labels, nclass)
    elif solver == "nmf":
        label_ce = nmf(labels, nclass, random_state)
    elif solver == "all":
        if verbose:
            print("    - ANMI:")
        ce_solvers = {"hgpa": hgpa, "mcla": mcla, "hbgf": hbgf}
        if labels.shape[1] <= 5000:
            ce_solvers["cspa"] = cspa
            ce_solvers["nmf"] = nmf
        best_objv = None
        for name, ce_solver in ce_solvers.items():
            if ce_solver == cspa or ce_solver == hbgf:
                label = ce_solver(labels, nclass)
            else:
                label = ce_solver(labels, nclass, random_state)
            objv = calc_objective(labels, label)
            if verbose:
                print("        -", name, ":", objv)
            if best_objv is None:
                best_objv = objv
                best_solver = name
                label_ce = label
            if best_objv < objv:
                best_objv = objv
                best_solver = name
                label_ce = label
        if verbose:
            print("    - Best solver:", best_solver)
    else:
        raise ValueError(
            f"Invalid solver parameter: Got '{solver}' instead of \
                one of ('cspa', 'hgpa', 'mcla', 'hbgf', 'nmf', 'all')"
        )

    return label_ce